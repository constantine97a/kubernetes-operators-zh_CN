# 运行 Operators
[TOC]

在本章的第一部分，我们概述了运行本书中示例的要求，并就如何建立对满足这些要求的Kubernetes集群的访问提供了建议。在第二部分中，您将使用该集群进行安装和使用一个Operator来研究Operator。

到最后，您将拥有一个Kubernetes集群用作Operator测试平台，并且您将知道如何通过一组清单(Manifests)在其上部署现有Operator。
您还将看到Operator在面对更改和故障时管理其应用程序的特定内部状态，从而增加您对后续章节中介绍的Operator架构和构建工具的理解

## 安装 Operator Lab

要在以下章节中构建、测试和运行Operator，您需要集群管理员访问运行Kubernetesv1.11.0或更高版本的集群。如果您已经满足这些要求，则可以跳到下一部分。在本节中，我们向需要搭建Kubernetes集群或需要在本地环境进行Operator开发和测试的读者提供一般性建议。

### 集群版本的要求

我们已经使用Kubernetes版本v1.11到v1.16测试了本书中的示例。我们将说明我们检查的任何功能或操作何时需要高于v1.11的版本。

#### 控制平台的可扩展性

Kubernetes1.2版引入了称为CRD的API扩展机制，以元素形式作为第三方资源( third party resource TPR)。从那时起，Operators构建的组件已经成倍增长和成熟，如图2‑1所示。CRD在Kubernetes1.7版本中正式化。

![](D:\Kubernete Operator\images\2-1.png)

Figure 2-1. 每个 Kubernetes 版本的可扩展性功能

正如您在第1章中看到的，*CRD*是特定集群的Kubernetes API中新的、特定于站点的资源（或API端点）的定义。*CRD*是Operator模式最基本描述的两个基本构建块之一:管理CR的自定义控制器。

### 授权要求

由于Operators扩展了Kubernetes本身，因此您需要对Kubernetes集群具有特权的、集群范围的访问权限来部署它们，例如常见的*cluster-admin* 集群角色。

<img src="./images/note.png" alt="note" style="zoom:10%;" />[^i]  权限较低的用户可以使用Operator管理的服务和应用程序——这些服务和应用程序，我们称之为“*Operand*”（操作数）。

虽然您应该为生产场景配置更加精细的Kubernetes -- 基于角色的访问控制(RBAC)，但完全控制集群意味着您将能够立即部署CRD和Operator。
在为Operator及其管理的应用程序开发角色（Role）、服务帐户(Service Account)和绑定(Binding)时，您还可以声明更详细的RBAC。

您可以向*Kubernetes API*请求有关*cluster‑admin*角色的信息，以查看它是否存在于您的集群中。以下*shell*摘录显示了如何使用kubectl的describe子命令获取角色（role）摘要:
```shell
$ kubectl describe clusterrole cluster-admin
Name: cluster-admin 【1】
Labels: kubernetes.io/bootstrapping=rbac-defaults
PolicyRule:
 Resources Non-Resource URLs Resource Names Verbs
 --------- ----------------- -------------- -----
 *.*       []                []             [*]
           [*]               []             [*]

```
【1】RBAC cluster‑admin ClusterRole：可以执行一切。

### 标准工具和技术
Operator的目标是让他们管理的复杂应用程序成为 Kubernetes API 的一等公民。 我们将在以下章节的示例中展示这意味着什么。 在这个阶段，这意味着最新版本的命令行 Kubernetes API 工具 -- kubectl， 是在集群上部署基本 Operator 并与之交互的唯一要求。

需要安装或更新 kubectl 的读者请查阅当前文档（https://oreil.ly/ke6KM）。 

<img src="./images/note.png" alt="note" style="zoom:10%;" />[^i]  :Red Hat OpenShift Kubernetes 发行版（如下所述）的用户可以选择（并且可以互换）使用 *oc* (OpenShift API )实用程序来代替 *kubectl*。

### 建议的集群配置

运行 Kubernetes 集群的方法有很多种，您可以在其中部署 *Operator*。 如前所述，如果您已经在运行最新的 Kubernetes 版本，则可以跳过此建议并继续第 15 页的“*运行简单的操作符*”。
如果您不是，我们已经对本节中描述的 *Kubernetes 发布* 或发行版进行了足够的测试，以期望它们能够支持本书中的练习。

#### Minikube

Minikube v1.5.2 (https://oreil.ly/dBPzK) 部署了 Kubernetes v1.16.2。它在本地系统管理程序的虚拟机 (VM) 中运行单节点 Kubernetes 集群。 
默认情况下，Minikube 希望使用 VirtualBox，因为它具有广泛的可用性，但通过一些额外的步骤，它还可以使用您平台的本机管理程序，例如 Linux 上的 KVM、Windows 上的 Hyper-V，或 macOS 上的 HyperKit 和 Hypervisor.framework。 我们在这里避免详细的安装说明，因为它们最好留给 Minikube 文档 (https://oreil.ly/eRZpQ)。我们已经使用 Minikube 对本书中的示例进行了最彻底的测试，出于方便和成本的原因，我们建议您使用类似它的本地环境、CodeReady 容器（请参阅下一节）或使用 Docker 中的 Kubernetes 开始您的 Operator 实验 （Kind）（https://oreil.ly/2y6PD）。

#### Red Hat OpenShift
*OpenShift* 是 Red Hat 的 Kubernetes 发行版。您可以在 Kubernetes 上执行的任何操作，都可以在等效核心版本的 OpenShift 上执行。 （在 Kubernetes 上还构建了特定于 OpenShift 的功能，但这些超出了本书的范围）OpenShift 版本 4 提供了一个功能齐全的 Kubernetes 发行版，该发行版本身是使用 Operators 设计、交付和管理的。它是一个“自托管”的 Kubernetes，能够执行就地平台升级，而不会导致托管工作负载停机。 
OpenShift 包括第 4 章中描述的 Operator Lifecycle Manager，以及开箱即用的 Operator Catalog 分发机制的图形界面。 
您可以通过访问 *Red Hat* 的 https://try.openshi.com 在 *Amazon Web Services* (AWS)、*Microsoft Azure* 或 *Google Cloud Platform* 上部署一个成熟的 *OpenShift v4* 集群，并获得免费试用许可证。

<img src="./images/tips.png" alt="note" style="zoom:10%;" />  要在您的笔记本电脑上运行 OpenShift，请查看 Minikube 的等价物 Red Hat CodeReady Containers (https://github.com/codeready/crc)

```text
OpenShift Learning Portal
OpenShift 学习门户提供指导课程，包括访问具有安装、部署和管理 Operator 所需的所有权限的集群。 场景在您的网络浏览器中可用，使您可以轻松地在本书中的示例之外继续学习。每个会话都会启动一个 OpenShift 集群，您可以通过命令行和 Web GUI 访问它。请访问 https://learn.openshi.com 并选择“Building Operators on OpenShift”主题组。
```

### 检查您的集群版本
通过运行 *kubectl version* 来验证您的集群是否正在运行 *Kubernetes v1.11* 或更高版本。 此命令将为您的 kubectl 可执行文件返回一个 API 版本字符串，并为它所连接的集群返回第二个版本字符串：

```shell
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.2",
GitCommit:"c97fe5036ef3df2967d086711e6c0c405941e14b", GitTreeState:"clean",
BuildDate:"2019-10-15T19:18:23Z", GoVersion:"go1.12.10", Compiler:"gc",
Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.2",
GitCommit:"c97fe5036ef3df2967d086711e6c0c405941e14b", GitTreeState:"clean",
BuildDate:"2019-10-15T19:09:08Z", GoVersion:"go1.12.10", Compiler:"gc",
Platform:"linux/amd64"}

```

在上述输出中，客户端和服务器都运行 Kubernetes 版本 1.16.2。 虽然比服务器低一个版本的 kubectl 客户端应该可以工作（https://oreil.ly/I7K1e），
但为简单起见，您应该确保您的客户端和服务器次要版本匹配。 如果您有 v1.11 或更高版本，您就可以开始试验 Operator。

## 运行一个简单的*Operator*

一旦你确认你对一个兼容版本的 Kubernetes 集群有特权访问，你就可以部署一个 Operator，看看 Operator 能做什么。 稍后，当您部署和测试您构建的 Operator 时，您将再次看到相同过程。 etcd Operator 直接自动化的恢复和升级显示了 Kubernetes Operator 的原则和目标。

### 一个共同的起点

etcd (https://github.com/coreos/etcd) 是一个分布式键值存储，其根植于 CoreOS，现在由云原生计算基金会赞助。它是 Kubernetes 核心的底层数据存储，也是几个分布式应用程序的关键部分。etcd 通过实现一个称为 Raft (https://raft.github.io/) 的协议来提供可靠的存储，该协议保证了法定人数之间的共识。

etcd 运算符通常用作*Operator*模式的价值和机制的一种“Hello World”示例，我们在这里遵循这一传统。 我们回到它是因为 etcd 的最基本用法不难说明，但是 etcd 集群部署和管理需要有应用程序特定的、知其然的特定领域技术，这些知识会被融入到Operator中。要使用 etcd，您需要将键和值放入，然后按名称将它们取出。创建至少三个或更多节点的可靠 etcd 集群需要配置端点、身份验证和其他通常留给 etcd 专家（或他们的自定义 shell 脚本集合）的问题。
随着时间的推移保持 etcd 运行和升级需要持续的管理。 etcd Operator 知道如何完成所有这些工作。

在接下来的部分中，您将部署 etcd Operator，然后让它根据您的要求规范创建一个 etcd 集群。您将让 *Operator* 从故障中恢复并执行版本升级，同时 etcd API 能继续为读取和写入请求提供服务，展示 *Operator* 如何自动化基础软件的生命周期。

<img src="./images/note.png" alt="note" style="zoom:10%;" />:您无需在 OpenShift 学习门户 (https://oreil.ly/j-xKh) 上进行任何设置，即可在运行的 OpenShift 集群上遵循此示例。

### 获取 etcd Operator Manifests
本书为每一章的示例代码提供了一个随同的 Git 存储库（https://github.com/kubernetesoperators-book/chapters.git）。 获取章节仓库并切换到第 3 章的示例目录，如下所示：
```shell
$ git clone https://github.com/kubernetes-operators-book/chapters.git
$ cd chapters/ch03
```

### CRs: Custom API Endpoints
与 *Kubernetes* 中的几乎所有内容一样，*YAML* 清单描述了 *CRD*。 CR 是 *Kubernetes API* 中的一个*命名端点*（*endpoint*）。 一个名为 *etcdclusters.etcd.data base.coreos.com* 的 *CRD* 代表新类型的*endpoint*。

#### 创建 CRD

使用 _cat、less_ 或您喜欢的工具来读取名为 _etcd-operator-crd.yaml_ 的文件。 您将看到如下内容，即指定 _Etcd Cluster CRD_ 的 *YAML*：

```shell
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
 name: etcdclusters.etcd.database.coreos.com
spec:
 group: etcd.database.coreos.com
 names:
 kind: EtcdCluster
 listKind: EtcdClusterList
 plural: etcdclusters
 shortNames:
 - etcdclus
 - etcd
 singular: etcdcluster
 scope: Namespaced
 versions:
 - name: v1beta2
   served: true
   storage: true
```
*CRD* 定义了 Kubernetes API 应该如何引用这个新资源。 帮助您在 kubectl 中减少输入的缩短昵称也在此处定义。

在集群上创建 *CRD*：
```shell
$ kubectl create -f etcd-operator-crd.yaml
```
快速检查新的 *CRD*,  _etcdclusters.etcd.database.coreos.com_:

```shell
$ kubectl get crd
NAME                                   CREATED AT
etcdclusters.etcd.database.coreos.com  2019-11-15T02:50:14Z
```

<img src="./images/note.png" alt="note" style="zoom:10%;" />: CR 的*group*、*version*和kind共同构成了 Kubernetes 资源类型的完全限定名称。 该规范名称在集群中必须是唯一的。 您创建的 *CRD* 代表 etcd.database.coreos.com 组中的资源，*version*为 v1beta2，*kind*为 *EtcdCluster*。

### 我是谁：定义*Operator*的 *Service Account*

在第 3 章中，我们将概述 Kubernetes 授权(authorization)并定义服务帐户(service account)、角色(role)和其他授权概念。 现在，我们只想先看一下*Service Accoun*t的基本声明以及该帐户运行 *etcd Operator* 所需的功能。

**文件 etcd-operator-sa.yaml 定义了服务帐户：**

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
 name: etcd-operator-sa

```

如果您检查集群服务帐户列表，您会看到：

```shell
$ kubectl get serviceaccounts
NAME     SECRETS AGE
builder  2       2h
default  3       2h
deployer 2       2h
etcd-operator-sa 2 3s
[...]
```

#### 角色(Role)

管理服务帐户的角色在名为 etcd-operator-role.yaml 的文件中定义。 我们将在后面的章节和附录 C 中详细讨论 RBAC，但我们能在角色清单中能看见关键的条目。我们为角色命名，我们将从其他地方引用该名称：*etcd-operator-role*。 *YAML* 继续列出角色可能使用的资源种类（resources），以及它可以用它们做什么（verbs），也就是说-- 动词（verbs）。

```shell
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: etcd-operator-role
rules:
- apiGroups:
  - etcd.database.coreos.com
  resources:
  - etcdclusters
  - etcdbackups
  - etcdrestores
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - persistentvolumeclaims
  - events
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - deployments
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
```

**与服务帐户一样，使用 kubectl 创建角色：**

```shell
$ kubectl create -f etcd-operator-role.yaml
role.rbac.authorization.k8s.io/etcd-operator-role created
```

#### 角色绑定(Role binding)
*RBAC* 配置的最后一位 *RoleBinding* 将Role分配给 *etcd operator* 的*service account*。 它在文件 *etcd-operator-rolebinding.yaml* 中声明：

```shell
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: etcd-operator-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: etcd-operator-role
subjects:
- kind: ServiceAccount
  name: etcd-operator-sa
  namespace: default
```

注意最后一行。 如果您在一个全新的 *OpenShift* 集群上，例如 CodeReady Containers 提供的集群, 默认情况下，您的 kubectl 或 oc 命令将在命名空间 myproject 中运行。如果您在类似未配置的 *Kubernetes* 集群上，则您的上下文的默认值通常是命名空间默认值。无论您身在何处，此 RoleBinding 中的命名空间值都必须与您正在工作的集群上的命名空间(*namespace*)相匹配。

现在创建绑定：


```shell
$ kubectl create -f etcd-operator-rolebinding.yaml
rolebinding.rbac.authorization.k8s.io/etcd-operator-rolebinding created
```

### 部署 etcd Operator

Operator 是在 pod 中运行的自定义控制器，它监视您之前定义的 EtcdCluster CR。 清单文件 etcd-operator-deployment.yaml 列出了 Operator pod 的规范，包括您正在部署的 Operator 的容器镜像。**请注意，它没有定义 etcd 集群的规范**。一旦 Operator 运行，您将在 CR 中向已部署的 etcd Operator 描述所需的 etcd 集群：

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
 labels:
    name: etcdoperator
 name: etcd-operator
spec:
    replicas: 1
    selector:
      name: etcd-operator
    template:
      name: etcd-operator
      spec:
        containers:
          - name: etcd-operator
        image: quay.io/coreos/etcd-operator:v0.9.4
        command:
          - etcd-operator
          - --create-crd=false
        [...]
        imagePullPolicy: IfNotPresent
        serviceAccountName: etcd-operator-sa
```

部署为您的 Operator 提供标签和名称。这里需要注意的一些关键条目是要在此部署的 pod 中运行的容器映像 etcd:operator:v0.9.4，以及部署资源应用于访问集群的 Kubernetes API 的服务帐户。etcd-operator 部署使用为其创建的 etcd:operator-sa 服务帐户。

像往常一样，您可以通过清单在集群上创建此资源：
```shell
$ kubectl create -f etcd-operator-deployment.yaml
deployment.apps/etcd-operator created
$ kubectl get deployments
NAME            DESIRED     CURRENT     UP-TO-DATE    AVAILABLE     AGE
etcd-operator   1           1           1             1             19s
```
etcd Operator 本身就是在该部署中运行的 pod。 在这里你可以看到它正在启动：

```shell
$ kubectl get pods
NAME                           READY STATUS            RESTARTS AGE
etcd-operator-594fbd565f-4fm8k 0/1   ContainerCreating 0        4s
```

### 申明etcd cluster
之前，您创建了一个 CRD，定义了一种新的资源类型（kind），即 EtcdCluster。 现在您有一个 Operator 正在监视 EtcdCluster 资源，您可以声明一个具有所需状态的 EtcdCluster。 为此，请提供 Operator 认可的两个规范元素：size - etcd 集群成员的数量以及 version - 每个成员应运行的 etcd 版本。

您可以在文件 *etcd-cluster-cr.yaml* 中查看*spec*节点：
```yaml
apiVersion: etcd.database.coreos.com/v1beta2
kind: EtcdCluster
metadata:
 name: example-etcd-cluster
spec:
 size: 3
 version: 3.1.10

```

这个简短的清单声明了三个集群成员的期望状态(desired state)，每个成员运行 3.1.10 版本的 etcd 服务器。使用熟悉的 kubectl 语法创建这个 etcd 集群：

```shell
$ kubectl create -f etcd-cluster-cr.yaml
etcdcluster.etcd.database.coreos.com/example-etcd-cluster created
$ kubectl get pods -w
NAME                            READY STATUS  RESTARTS AGE
etcd-operator-594fbd565f-4fm8k  1/1   Running 0        3m
example-etcd-cluster-95gqrthjbz 1/1   Running 2        38s
example-etcd-cluster-m9ftnsk572 1/1   Running 0        34s
example-etcd-cluster-pjqhm8d4qj 1/1   Running 0        31s
```

这个示例 etcd 集群是一等公民，是集群 API 中的 EtcdCluster。由于它是一个 API 资源，您可以直接从 Kubernetes 获取 etcd 集群规范和状态。尝试 kubectl describe 报告您的 etcd 集群的大小、etcd 版本和状态，如下所示：

```shell
$ kubectl describe etcdcluster/example-etcd-cluster
Name: example-etcd-cluster
Namespace: default
API Version: etcd.database.coreos.com/v1beta2
Kind: EtcdCluster
[...]
Spec:
  Repository: quay.io/coreos/etcd
  Size: 3
  Version: 3.1.10
Status:
  Client Port: 2379
  Conditions:
    Last Transition Time: 2019-11-15T02:52:04Z
    Reason: Cluster available
    Status: True
    Type: Available
    Current Version: 3.1.10
  Members:
    Ready:
      example-etcd-cluster-6pq7qn82g2
      example-etcd-cluster-dbwt7kr8lw
      example-etcd-cluster-t85hs2hwzb
  Phase: Running
  Service Name: example-etcd-cluster-client

```

###  操作ETCD 
你现在有一个正在运行的 etcd 集群。 etcd Operator 在 etcd 集群的命名空间中创建一个 Kubernetes 服务（https://oreil.ly/meXW_）。 服务(service)是客户端可以访问一组 pod 的端点，即使该组的成员可能会发生变化。 默认情况下，服务具有在集群中可见的 DNS 名称。 Operator 通过将 -client 附加到 CR 中定义的 etcd 集群名称来构造 etcd API 的客户端使用的服务的名称。 
在这里，客户端服务被命名为 *example-etcd-cluster-client*，它监听通常的 *etcd* 客户端 *IP* 端口 *2379*。*kubectl* 可以列出与 *etcd* 集群关联的服务：

```shell
$ kubectl get services --selector etcd_cluster=example-etcd-cluster
NAME                        TYPE      CLUSTER-IP   ... PORT(S)           AGE
example-etcd-cluster        ClusterIP None         ... 2379/TCP,2380/TCP 21h
example-etcd-cluster-client ClusterIP 10.96.46.231 ... 2379/TCP          21h

```


<img src="./images/note.png" alt="note" style="zoom:10%;" /> etcd Operator 创建的另一个服务 example-etcd -cluster 由 etcd 集群成员而不是 etcd API 客户端使用。

您可以在集群上运行 etcd 客户端并使用它连接到客户端服务并与 etcd API 交互。 以下命令使您进入 etcd 容器的shell：

```shell
$ kubectl run --rm -i --tty etcdctl --image quay.io/coreos/etcd \
 --restart=Never -- /bin/sh
```

在 etcd 容器的 shell 中，使用 etcdctl 的 put 和 get 动词在 etcd 中创建和读取键值对：


```shell
$ export ETCDCTL_API=3
$ export ETCDCSVC=http://example-etcd-cluster-client:2379
$ etcdctl --endpoints $ETCDCSVC put foo bar
$ etcdctl --endpoints $ETCDCSVC get foo
foo
bar
```

重复这些查询或在您继续进行的每个更改之后在 etcdctl shell 中运行新的 put 和 get 命令。 随着 etcd Operator 扩展集群、替换成员和升级 etcd 版本，您将看到 etcd API 服务的持续可用性。

### 扩展 etcd 集群
您可以通过更改声明的大小规范来扩展 etcd 集群。 编辑 etcd-cluster-cr.yaml 并将大小从 3 个更改为 4 个 etcd 成员。 将更改应用到 EtcdCluster CR：
```shell
$ kubectl apply -f etcd-cluster-cr.yaml
```
检查正在运行的 pod 会显示 Operator 在 etcd 集群中添加了一个新的 etcd 成员：
```shell
$ kubectl get pods
NAME                           READY  STATUS   RESTARTS AGE
etcd-operator-594fbd565f-4fm8k 1/1    Running  1        16m
example-etcd-cluster-95gqrthjbz 1/1   Running  2        15m
example-etcd-cluster-m9ftnsk572 1/1   Running  0        15m
example-etcd-cluster-pjqhm8d4qj 1/1   Running  0        15m
example-etcd-cluster-w5l67llqq8 0/1   Init:0/1 0        3s
```

<img src="D:\kubernetes-operators-zh_CN\images\tips.png" style="zoom:25%;" />您还可以尝试 kubectl edit etcdcluster/example-etcd cluster 放入编辑器并实时更改集群大小。


###  故障和自动恢复
您在第 1 章中看到了 etcd Operator 替换了一个失败的成员。在您看到它之前，有必要重申您必须手动处理此操作的一般步骤。 与无状态程序不同，没有 etcd pod 在真空中运行。 通常，一个人类的etcd“Operator”必须注意到一个成员的故障，执行一个新的副本，并为其提供配置，以便它可以与剩余的成员一起加入etcd集群。etcd Operator 了解 etcd 的内部状态并自动进行恢复。

#### 从失败的 etcd 成员中恢复
快速运行 kubectl get pods -l app=etc 以获取您的 etcdcluster 中的 pod 列表。 选择一个你不喜欢的，并告诉 Kubernetes 删除它：
```shell
$ kubectl delete pod example-etcd-cluster-95gqrthjbz
pod "example-etcd-cluster-95gqrthjbz" deleted
```
Operator 注意到集群上的现实与期望状态之间的差异，并添加了一个 etcd 成员来替换您删除的那个。 获取 Pod 列表时，您可以看到处于 PodInitializing 状态的 新的etcd 集群成员，如下所示：
```shell
$ kubectl get pods -w
NAME                            READY STATUS          RESTARTS AGE
etcd-operator-594fbd565f-4fm8k  1/1   Running         1        18m
example-etcd-cluster-m9ftnsk572 1/1   Running         0        17m
example-etcd-cluster-pjqhm8d4qj 1/1   Running         0        17m
example-etcd-cluster-r6cb8g2qqw 0/1   PodInitializing 0        31s
```
-w 开关告诉 kubectl “监视” pod 列表，并在列表的每次更改时在其标准输出上打印更新。 您可以使用 Ctrl-C 停止手表并返回到您的 shell 提示符。您可以检查事件以查看 example-etcd-cluster CR 中记录的恢复操作：

```shell
$ kubectl describe etcdcluster/example-etcd-cluster
[...]
Events:
 Normal Replacing Dead Member 4m etcd-operator-589c65bd9f-hpkc6
      The dead member example-etcd-cluster-95gqrthjbz is being replaced
 Normal Member Removed 4m etcd-operator-589c65bd9f-hpkc6
      Existing member example-etcd-cluster-95gqrthjbz removed from the cluster
[...]
```
在整个恢复过程中，如果您再次启动 etcd 客户端 pod，您可以向 etcd 集群发出请求，包括检查其总体健康状况：
```shell
$ kubectl run --rm -i --tty etcdctl --image quay.io/coreos/etcd \
 --restart=Never -- /bin/sh
If you don't see a command prompt, try pressing enter.
$ etcdctl --endpoints http://example-etcd-cluster-client:2379 cluster-health
member 5ee0dd47065a4f55 is healthy: got healthy result ...
member 70baca4290889c4a is healthy: got healthy result ...
member 76cd6c58798a7a4b is healthy: got healthy result ...
cluster is healthy
$ exit
pod "etcdctl" deleted
```

etcd Operator 从其复杂的有状态应用程序的故障中恢复，就像 Kubernetes 自动恢复无状态应用程序一样。 这在概念上很简单，但在操作上很强大。
基于这些概念，Operator可以执行更高级的技巧，例如升级他们管理的软件。自动化升级可以对安全产生积极影响，只要确保事情保持最新。 当Operator在保持服务可用性的同时对其应用程序执行滚动升级时，更容易使用最新修复程序为软件打补丁。

### 升级 etcd 集群
如果您碰巧已经是 etcd 用户，您可能已经注意到我们指定了旧版本 3.1.10。 我们设计了这个，以便我们可以探索 etcd Operator 的升级技能。 
#### 使用艰难方式进行升级
此时，您有一个运行版本 3.1.10 的 etcd 集群。 要升级到 etcd3.2.13，您需要执行一系列步骤。 由于这本书是关于 Operators 的，而不是 etcd 管理的，所以我们压缩了这里介绍的过程，撇开网络和主机级别的问题来概述手动升级过程。 手动升级的步骤如下：

1. 检查每个etcd节点的版本和健康情况。

2. 创建集群状态快照，用于容灾。

3. 停止一台 etcd 服务器。 用 v3.2.13 二进制文件替换现有版本。 启动新版本。

4. 对每个 etcd 集群成员重复 - 在三成员集群中至少再重复两次。

有关详细信息，请参阅 etcd 升级文档 (https://oreil.ly/II9Pn)。

#### 最简单的方法：让Operator来做
了解手动升级的重复和容易出错的过程后，更容易看到在 etcd Operator 中编码特定于 etcd 的知识的强大。 Operator 可以管理 etcd 版本，升级只需在 EtcdCluster 资源中声明新的所需版本即可。
#### 触发 etcd 升级
通过查询一些 etcd-cluster pod 来获取当前 etcd 容器镜像的版本，过滤输出以仅查看版本：
```shell
$ kubectl get pod example-etcd-cluster-795649v9kq \
 -o yaml | grep "image:" | uniq
image: quay.io/coreos/etcd:v3.1.10
image: busybox:1.28.0-glibc
```
或者，由于您在 Kubernetes API 中添加了 EtcdCluster 资源，因此您可以直接使用 kubectl describe 来总结 Operator 的 example-etcd-cluster Image，就像之前所做的那样：

```shell
$ kubectl describe etcdcluster/example-etcd-cluster
```
您将看到集群正在运行 etcd 版本 3.1.10，如文件 etcd-cluster cr.yaml 和从中创建的 CR 中指定的那样。

编辑 etcd-cluster-cr.yaml 并将版本规范从 3.1.10 更改为 3.2.13。 然后将新规范应用于集群上的资源：
```shell
$ kubectl apply -f etcd-cluster-cr.yaml
```
再次使用 describe 命令并查看当前版本和目标版本，以及 Events 节中的成员升级通知：
```shell
$ kubectl describe etcdcluster/example-etcd-cluster
Name: example-etcd-cluster
Namespace: default
API Version: etcd.database.coreos.com/v1beta2
Kind: EtcdCluster
[...]
Status:
 Conditions:
  [...]
  Message: upgrading to 3.2.13
  Reason: Cluster upgrading
  Status: True
  Type: Upgrading
  Current Version: 3.1.10
  [...]
 Size: 3
 Target Version: 3.2.13
Events:
 Type Reason Age From ...
 ---- ------ --- ---- ---
 Normal Member Upgraded 3s etcd-operator-594fbd565f-4fm8k ...
 Normal Member Upgraded 5s etcd-operator-594fbd565f-4fm8k ...
```

#### 升级升级
通过一些 kubectl 技巧，您可以直接通过 Kubernetes API 进行相同的编辑。 这一次，让我们从 3.2.13 升级到撰写本文时可用的最新的 etcd 次要版本，版本 3.3.12：
```shell
$ kubectl patch etcdcluster example-etcd-cluster --type='json' \
 -p '[{"op": "replace", "path": "/spec/version", "value":3.3.12}]'
```
请记住，您始终可以在 etcd 集群的 CR 清单中进行此更改，然后使用 kubectl 应用它，就像您在触发第一次升级时所做的那样。

连续的 kubectl describe etcdcluster/example-etcd-cluster 命令将显示从旧版本到目标版本的转换，直到该版本变为当前版本，此时您将看到 Current Version: 3.3.12。 事件部分记录了这些升级中的每一个：
```shell
 Normal Member Upgraded 1m etcd-operator-594fbd565f-4fm8k
 	Member example-etcd-cluster-pjqhm8d4qj upgraded from 3.1.10 to 3.2.23
 Normal Member Upgraded 27s etcd-operator-594fbd565f-4fm8k
	Member example-etcd-cluster-r6cb8g2qqw upgraded from 3.2.23 to 3.3.12
```

### 清理

在继续之前，如果您删除您创建和操作的资源以试验 etcd Operator，将会很有帮助。 如以下 shell摘抄所示，您可以使用用于创建资源的清单来删除资源。 首先，确保您当前的工作目录是您之前克隆的章节 Git 存储库中的 *ch03*（*cd chapters/ch03*）：

```shell
$ kubectl delete -f etcd-operator-sa.yaml
$ kubectl delete -f etcd-operator-role.yaml
$ kubectl delete -f etcd-operator-rolebinding.yaml
$ kubectl delete -f etcd-operator-crd.yaml
$ kubectl delete -f etcd-operator-deployment.yaml
$ kubectl delete -f etcd-cluster-cr.yaml
serviceaccount "etcd-operator-sa" deleted
rolebinding.rbac.authorization.k8s.io "etcd-operator-rolebinding" deleted
customresourcedefinition.apiextensions.k8s.io \
 "etcdclusters.etcd.database.coreos.com" deleted
deployment.apps "etcd-operator" deleted
etcdcluster.etcd.database.coreos.com "example-etcd-cluster" deleted
```

## 总结
为了简单起见，我们在这里使用 etcd API 和 etcdctl 工具，但应用程序使用 etcd 具有相同的 API 请求、存储、检索和监视键和范围。 etcd Operator 自动化了 etcd 集群部分，使可靠的键值存储可用于更多应用程序。

Operator变得相当复杂，需要管理各种关注点，正如您对应用程序特定扩展所期望的那样。尽管如此，大多数 Operator 都遵循 etcd Operator 中可辨别的基本模式：CR 指定一些期望的状态，例如应用程序的版本，并且自定义控制器监视资源，维护集群上的期望状态。

您现在拥有一个用于操作 Operator 的 Kubernetes 集群。您已经了解了如何部署 Operator 并触发它来执行特定于应用程序的状态协调（*reconciliation*）。接下来，我们将介绍 Operator 构建的 Kubernetes API 元素，然后介绍 Operator Framework 和 SDK，您将使用该工具包来构建 Operator。











